import os
import json
import re
import time
import subprocess
import threading
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

# ================= é…ç½®åŒºåŸŸ =================
# CSV ç›®å½• (ç”¨äºç›‘å¬æ¯”èµ›æ˜¯å¦å½»åº•ç»“æŸ)
CSV_DIR = r"D:\CS2Server\steamapps\common\Counter-Strike Global Offensive\game\csgo\MatchZy_Stats"
# TXT å¤‡ä»½ç›®å½• (åŒ…å«æ¯å›åˆè¯¦ç»†æ•°æ®çš„ csgo æ ¹ç›®å½•)
TXT_DIR = r"D:\CS2Server\steamapps\common\Counter-Strike Global Offensive\game\csgo"
# GitHub æ•°æ®å­˜å‚¨ç›®å½•
GITHUB_DATA_DIR = r"D:\CS2Server\Teio_Server\data"
# ============================================

def extract_val(pattern, text, default=0):
    m = re.search(pattern, text)
    return int(m.group(1)) if m else default

def extract_str(pattern, text, default=""):
    m = re.search(pattern, text)
    return m.group(1) if m else default

def get_final_txt_for_match(match_id):
    """åœ¨ TXT ç›®å½•ä¸­å¯»æ‰¾è¯¥ match_id å¯¹åº”çš„æœ€å¤§å›åˆæ•°å¤‡ä»½æ–‡ä»¶"""
    max_round = -1
    final_file = None
    # åŒ¹é…æ–‡ä»¶åå¦‚: matchzy_14_0_round21.txt
    pattern = re.compile(rf'matchzy_{match_id}_\d+_round(\d+)\.txt')
    
    if os.path.exists(TXT_DIR):
        for f in os.listdir(TXT_DIR):
            m = pattern.match(f)
            if m:
                round_num = int(m.group(1))
                if round_num > max_round:
                    max_round = round_num
                    final_file = os.path.join(TXT_DIR, f)
    return final_file

def sync_data():
    if not os.path.exists(GITHUB_DATA_DIR):
        os.makedirs(GITHUB_DATA_DIR)
    
    matches = []
    completed_match_ids = set()
    
    # 1. æ‰«æ CSV æ–‡ä»¶å¤¹ï¼Œè·å–æ‰€æœ‰ã€å·²å½»åº•æ‰“å®Œã€‘çš„æ¯”èµ› ID
    for root, dirs, files in os.walk(CSV_DIR):
        for f in files:
            if f.startswith("match_data_") and f.endswith(".csv"):
                mid_match = re.findall(r"(\d+).csv", f)
                if mid_match:
                    completed_match_ids.add(int(mid_match[0]))
                    
    # 2. é’ˆå¯¹æ¯ä¸ªå·²å®Œæˆçš„æ¯”èµ›ï¼Œå»è§£æå®ƒæœ€ç»ˆå›åˆçš„ txt æ•°æ®
    for match_id in completed_match_ids:
        txt_path = get_final_txt_for_match(match_id)
        if not txt_path:
            continue # å¦‚æœæ„å¤–æ‰¾ä¸åˆ°å¯¹åº”çš„ txt å¤‡ä»½ï¼Œåˆ™è·³è¿‡
            
        try:
            with open(txt_path, 'r', encoding='utf-8', errors='ignore') as file:
                content = file.read()
                
            # æå–å…¨å±€åŸºç¡€ä¿¡æ¯
            timestamp = extract_str(r'"timestamp"\s+"([^"]+)"', content, "æœªçŸ¥æ—¶é—´")
            team1_name = extract_str(r'"team1"\s+"([^"]+)"', content, "TEAM_1")
            team2_name = extract_str(r'"team2"\s+"([^"]+)"', content, "TEAM_2")
            map_name = extract_str(r'"map"\s+"([^"]+)"', content, "Unknown")
            total_rounds = extract_val(r'"round"\s+"(\d+)"', content, 24)
            
            # è‡ªåŠ¨è®¡ç®—æ€»æ¯”åˆ† (åŒ…å«ä¸Šä¸‹åŠåœºå’ŒåŠ æ—¶èµ›)
            t1_score, t2_score = 0, 0
            for block in ['FirstHalfScore', 'SecondHalfScore', 'OvertimeScore']:
                b_match = re.search(rf'"{block}"\s*{{([^}}]+)}}', content)
                if b_match:
                    t1_score += extract_val(r'"team1"\s+"(\d+)"', b_match.group(1))
                    t2_score += extract_val(r'"team2"\s+"(\d+)"', b_match.group(1))
                    
            # åˆ†å‰²ä¸Šä¸‹åŠåœºçš„ç©å®¶æ•°æ®ï¼Œç¡®å®šé˜Ÿä¼å½’å±
            team2_index = content.find('"PlayersOnTeam2"')
            if team2_index == -1: team2_index = len(content)
            
            players = []
            names = [m for m in re.finditer(r'\t\t\t"name"\s+"([^"]+)"', content)]
            for i, n_match in enumerate(names):
                start_idx = n_match.start()
                end_idx = names[i+1].start() if i+1 < len(names) else len(content)
                chunk = content[start_idx:end_idx]
                
                team = team1_name if start_idx < team2_index else team2_name
                name = n_match.group(1)
                
                k = extract_val(r'"kills"\s+"(\d+)"', chunk)
                d = extract_val(r'"deaths"\s+"(\d+)"', chunk)
                a = extract_val(r'"assists"\s+"(\d+)"', chunk)
                k3 = extract_val(r'"enemy3Ks"\s+"(\d+)"', chunk)
                k4 = extract_val(r'"enemy4Ks"\s+"(\d+)"', chunk)
                k5 = extract_val(r'"enemy5Ks"\s+"(\d+)"', chunk)
                
                totals_match = re.search(r'"Totals"\s*{([^}]+)}', chunk)
                totals_chunk = totals_match.group(1) if totals_match else chunk
                
                dmg = extract_val(r'"Damage"\s+"(\d+)"', totals_chunk)
                entry = extract_val(r'"EntryWins"\s+"(\d+)"', totals_chunk)
                c1v1 = extract_val(r'"1v1Wins"\s+"(\d+)"', totals_chunk)
                c1v2 = extract_val(r'"1v2Wins"\s+"(\d+)"', totals_chunk)
                
                players.append({
                    "name": name, "team": team, 
                    "k": k, "d": d, "a": a, 
                    "dmg": dmg, "entry": entry, "clutch": c1v1 + c1v2,
                    "k3": k3, "k4": k4, "k5": k5
                })
                
            matches.append({
                "id": match_id,
                "timestamp": timestamp,
                "map": map_name,
                "team1": team1_name,
                "team2": team2_name,
                "team1_score": t1_score,
                "team2_score": t2_score,
                "total_rounds": total_rounds,
                "players": players
            })
        except Exception as e:
            print(f"è§£ææ–‡ä»¶ {txt_path} æ—¶å‡ºé”™: {e}")
            
    matches.sort(key=lambda x: x['id'], reverse=True)
    with open(os.path.join(GITHUB_DATA_DIR, "matches.json"), "w", encoding="utf-8") as f:
        json.dump(matches, f, indent=4, ensure_ascii=False)
    print(f"ğŸ“Š åŒæ­¥å®Œæˆï¼šå…±æå– {len(matches)} åœºæ ¸å¿ƒæ•°æ®ã€‚")

def run_git_push():
    repo_root = GITHUB_DATA_DIR
    try:
        subprocess.run(["git", "add", "."], cwd=repo_root, check=True)
        status = subprocess.run(["git", "status", "--porcelain"], cwd=repo_root, capture_output=True, text=True)
        if status.stdout.strip():
            subprocess.run(["git", "commit", "-m", "Auto-update true HLTV stats"], cwd=repo_root, check=True)
            subprocess.run(["git", "push"], cwd=repo_root, check=True)
            print("ğŸš€ æ•°æ®å·²æé€Ÿæ¨é€è‡³äº‘ç«¯ï¼")
    except Exception as e:
        print(f"âŒ Git æ¨é€å¤±è´¥: {e}")

def handle_new_match():
    time.sleep(2) # ç­‰å¾… CSV å½»åº•å†™å…¥å®Œæ¯•
    sync_data()
    run_git_push()

class MatchHandler(FileSystemEventHandler):
    def on_created(self, event):
        # æ ¸å¿ƒä¿®å¤ï¼šä»…ç›‘å¬ CSV ä½œä¸ºæ¯”èµ›ç»“æŸçš„è§¦å‘å™¨
        if event.src_path.endswith(".csv") and "match_data_" in os.path.basename(event.src_path):
            print(f"ğŸ æ£€æµ‹åˆ°æ¯”èµ›ç»“æŸ (CSVå·²ç”Ÿæˆ): {os.path.basename(event.src_path)}")
            # å¼€æ–°çº¿ç¨‹å¤„ç†ï¼Œé˜²æ­¢é˜»å¡ watchdog
            threading.Thread(target=handle_new_match).start()

if __name__ == "__main__":
    sync_data() # å¯åŠ¨æ—¶å…ˆåŸºäºç°æœ‰çš„ CSV å’Œ TXT ç®—ä¸€éå­˜é‡æ•°æ®
    run_git_push()
    
    observer = Observer()
    # ç›‘å¬ CSV ç›®å½•
    observer.schedule(MatchHandler(), CSV_DIR, recursive=True)
    observer.start()
    print("ğŸ‘€ æˆ˜ç»©ç›‘æ§å¼•æ“ (å®Œç¾ç‰ˆ) å·²å¯åŠ¨ï¼Œæ­£åœ¨ç­‰å¾…æ¯”èµ›ç»“æŸ...")
    try:
        while True: time.sleep(1)
    except KeyboardInterrupt: observer.stop()
    observer.join()